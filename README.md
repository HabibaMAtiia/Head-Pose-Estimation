# Head Pose Estimation using Machine Learning & Mediapipe

## ğŸ“Œ Project Overview
This project implements a **head pose estimation system** that predicts the **pitch, yaw, and roll angles** of a face from video input.  
It leverages **Mediapipe FaceMesh** for landmark extraction and machine learning models (**SVR & Random Forest**) for regression.  
Models are trained, evaluated, and saved using **joblib** for production-ready deployment.

## ğŸš€ Features
- Extracts facial landmarks using **Mediapipe**  
- Preprocesses data for ML models  
- Trains and evaluates regression models (SVR & RF)  
- Achieved strong performance:  
  - Pitch â†’ **MSE: 62.36, RÂ²: 0.726**  
  - Yaw â†’ **MSE: 116.87, RÂ²: 0.866**  
  - Roll â†’ **MSE: 36.65, RÂ²: 0.884**  
- Saves models with **joblib** for deployment  
- Annotates head pose axes on video and saves the output  

## ğŸ› ï¸ Tech Stack
- **Python**  
- **Mediapipe** (FaceMesh for landmarks)  
- **Scikit-learn** (SVR, Random Forest)  
- **OpenCV** (video processing & visualization)  
- **Joblib** (model persistence)  


## âš¡ How to Run
1. **Clone the repository**  
   ```bash
   git clone https://github.com/your-username/head-pose-estimation.git
   cd head-pose-estimation
2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   
